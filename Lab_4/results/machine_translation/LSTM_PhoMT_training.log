2025-12-10 23:40:41,714 - INFO - ==================================================
2025-12-10 23:40:41,714 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:40:41,715 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:40:41,716 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:40:41,720 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:40:41,720 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:40:41,721 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}}
2025-12-10 23:40:41,739 - INFO - Using device: cuda
2025-12-10 23:40:42,499 - INFO - Loading dataset: pho_mt
2025-12-10 23:40:42,499 - ERROR - Error loading or splitting dataset: 'Vocab' object has no attribute 'total_labels'
Traceback (most recent call last):
  File "E:\DS201.Q11\DS201\Lab_4\main.py", line 142, in main
    num_classes = vocab.total_labels
                  ^^^^^^^^^^^^^^^^^^
AttributeError: 'Vocab' object has no attribute 'total_labels'
2025-12-10 23:41:17,115 - INFO - ==================================================
2025-12-10 23:41:17,115 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:41:17,115 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:41:17,115 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:41:17,115 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:41:17,115 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:41:17,115 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}}
2025-12-10 23:41:17,131 - INFO - Using device: cuda
2025-12-10 23:41:17,783 - INFO - Loading dataset: pho_mt
2025-12-10 23:41:17,783 - ERROR - Error loading or splitting dataset: PhoMTDataset.__init__() got an unexpected keyword argument 'path'
Traceback (most recent call last):
  File "E:\DS201.Q11\DS201\Lab_4\main.py", line 148, in main
    train_data = DatasetClass(path=dataset_info['train_path'], vocab=vocab, config=config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: PhoMTDataset.__init__() got an unexpected keyword argument 'path'
2025-12-10 23:42:35,581 - INFO - ==================================================
2025-12-10 23:42:35,581 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:42:35,581 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:42:35,581 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:42:35,581 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:42:35,581 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:42:35,581 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}}
2025-12-10 23:42:35,603 - INFO - Using device: cuda
2025-12-10 23:42:36,232 - INFO - Loading dataset: pho_mt
2025-12-10 23:42:36,232 - ERROR - Error loading or splitting dataset: PhoMTDataset.__init__() got an unexpected keyword argument 'config'
Traceback (most recent call last):
  File "E:\DS201.Q11\DS201\Lab_4\main.py", line 148, in main
    train_data = DatasetClass(path=dataset_info['train_path'], vocab=vocab, config=config)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: PhoMTDataset.__init__() got an unexpected keyword argument 'config'
2025-12-10 23:43:23,609 - INFO - ==================================================
2025-12-10 23:43:23,612 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:43:23,612 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:43:23,612 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:43:23,612 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:43:23,612 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:43:23,612 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}}
2025-12-10 23:43:23,628 - INFO - Using device: cuda
2025-12-10 23:43:24,265 - INFO - Loading dataset: pho_mt
2025-12-10 23:43:24,299 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-10 23:46:37,613 - INFO - ==================================================
2025-12-10 23:46:37,613 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:46:37,613 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:46:37,613 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:46:37,615 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:46:37,615 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:46:37,615 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-10 23:46:37,621 - INFO - Using device: cuda
2025-12-10 23:46:38,279 - INFO - Loading dataset: pho_mt
2025-12-10 23:46:38,313 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-10 23:46:38,654 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-10 23:46:40,035 - INFO - START TRAINING LSTM_PhoMT...
2025-12-10 23:46:40,036 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-10 23:48:58,568 - INFO - ==================================================
2025-12-10 23:48:58,568 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:48:58,570 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:48:58,570 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:48:58,571 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:48:58,571 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:48:58,571 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-10 23:48:58,584 - INFO - Using device: cuda
2025-12-10 23:48:59,202 - INFO - Loading dataset: pho_mt
2025-12-10 23:48:59,245 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-10 23:48:59,481 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-10 23:49:00,428 - INFO - START TRAINING LSTM_PhoMT...
2025-12-10 23:49:00,428 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-10 23:49:48,504 - INFO - ==================================================
2025-12-10 23:49:48,504 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:49:48,504 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:49:48,504 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:49:48,504 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:49:48,508 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:49:48,508 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-10 23:49:48,523 - INFO - Using device: cuda
2025-12-10 23:49:49,161 - INFO - Loading dataset: pho_mt
2025-12-10 23:49:49,198 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-10 23:49:49,437 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-10 23:49:50,393 - INFO - START TRAINING LSTM_PhoMT...
2025-12-10 23:49:50,393 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-10 23:52:00,362 - INFO - ==================================================
2025-12-10 23:52:00,363 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:52:00,363 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:52:00,363 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:52:00,367 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:52:00,367 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:52:00,367 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-10 23:52:00,376 - INFO - Using device: cuda
2025-12-10 23:52:01,100 - INFO - Loading dataset: pho_mt
2025-12-10 23:52:01,136 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-10 23:52:01,372 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-10 23:52:02,342 - INFO - START TRAINING LSTM_PhoMT...
2025-12-10 23:52:02,342 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-10 23:56:40,815 - INFO - ==================================================
2025-12-10 23:56:40,815 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:56:40,816 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:56:40,816 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:56:40,819 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:56:40,819 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:56:40,819 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-10 23:56:40,836 - INFO - Using device: cuda
2025-12-10 23:56:41,480 - INFO - Loading dataset: pho_mt
2025-12-10 23:56:41,515 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-10 23:56:41,764 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-10 23:56:42,762 - INFO - START TRAINING LSTM_PhoMT...
2025-12-10 23:56:42,762 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-10 23:58:01,522 - INFO - ==================================================
2025-12-10 23:58:01,522 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:58:01,522 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:58:01,522 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:58:01,524 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:58:01,524 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:58:01,524 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-10 23:58:01,538 - INFO - Using device: cuda
2025-12-10 23:58:02,187 - INFO - Loading dataset: pho_mt
2025-12-10 23:58:02,221 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-10 23:58:02,459 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-10 23:58:03,420 - INFO - START TRAINING LSTM_PhoMT...
2025-12-10 23:58:03,421 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-10 23:59:01,253 - INFO - ==================================================
2025-12-10 23:59:01,253 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:59:01,253 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:59:01,253 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:59:01,257 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:59:01,257 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:59:01,257 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-10 23:59:01,271 - INFO - Using device: cuda
2025-12-10 23:59:01,927 - INFO - Loading dataset: pho_mt
2025-12-10 23:59:01,966 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-10 23:59:02,240 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-10 23:59:03,266 - INFO - START TRAINING LSTM_PhoMT...
2025-12-10 23:59:03,266 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-10 23:59:16,072 - INFO - ==================================================
2025-12-10 23:59:16,072 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-10 23:59:16,072 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-10 23:59:16,072 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-10 23:59:16,074 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-10 23:59:16,075 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-10 23:59:16,075 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-10 23:59:16,087 - INFO - Using device: cuda
2025-12-10 23:59:16,733 - INFO - Loading dataset: pho_mt
2025-12-10 23:59:16,766 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-10 23:59:17,003 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-10 23:59:18,034 - INFO - START TRAINING LSTM_PhoMT...
2025-12-10 23:59:18,034 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:00:27,463 - INFO - ==================================================
2025-12-11 00:00:27,464 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:00:27,464 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:00:27,464 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:00:27,468 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:00:27,468 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:00:27,468 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:00:27,485 - INFO - Using device: cuda
2025-12-11 00:00:28,226 - INFO - Loading dataset: pho_mt
2025-12-11 00:00:28,266 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:00:28,553 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:00:29,620 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:00:29,620 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:01:29,774 - INFO - ==================================================
2025-12-11 00:01:29,775 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:01:29,775 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:01:29,775 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:01:29,779 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:01:29,779 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:01:29,779 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:01:29,794 - INFO - Using device: cuda
2025-12-11 00:01:30,445 - INFO - Loading dataset: pho_mt
2025-12-11 00:01:30,478 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:01:30,751 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:01:31,759 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:01:31,759 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:01:51,608 - INFO - ==================================================
2025-12-11 00:01:51,608 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:01:51,609 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:01:51,609 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:01:51,611 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:01:51,611 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:01:51,612 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:01:51,624 - INFO - Using device: cuda
2025-12-11 00:01:52,307 - INFO - Loading dataset: pho_mt
2025-12-11 00:01:52,341 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:01:52,601 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:01:53,656 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:01:53,656 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:02:37,629 - INFO - ==================================================
2025-12-11 00:02:37,630 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:02:37,630 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:02:37,630 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:02:37,632 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:02:37,633 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:02:37,633 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:02:37,647 - INFO - Using device: cuda
2025-12-11 00:02:38,338 - INFO - Loading dataset: pho_mt
2025-12-11 00:02:38,372 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:02:38,646 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:02:39,629 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:02:39,630 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:03:13,668 - INFO - ==================================================
2025-12-11 00:03:13,669 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:03:13,669 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:03:13,669 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:03:13,671 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:03:13,671 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:03:13,671 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:03:13,682 - INFO - Using device: cuda
2025-12-11 00:03:14,334 - INFO - Loading dataset: pho_mt
2025-12-11 00:03:14,366 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:03:14,609 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:03:15,626 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:03:15,627 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:04:12,325 - INFO - ==================================================
2025-12-11 00:04:12,325 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:04:12,326 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:04:12,326 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:04:12,327 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:04:12,327 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:04:12,327 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:04:12,341 - INFO - Using device: cuda
2025-12-11 00:04:12,985 - INFO - Loading dataset: pho_mt
2025-12-11 00:04:13,019 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:04:13,264 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:04:14,214 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:04:14,214 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:05:24,464 - INFO - ==================================================
2025-12-11 00:05:24,464 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:05:24,465 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:05:24,465 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:05:24,467 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:05:24,467 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:05:24,467 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:05:24,480 - INFO - Using device: cuda
2025-12-11 00:05:25,179 - INFO - Loading dataset: pho_mt
2025-12-11 00:05:25,213 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:05:25,454 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:05:26,435 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:05:26,435 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:16:29,654 - INFO - ==================================================
2025-12-11 00:16:29,654 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:16:29,655 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:16:29,655 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:16:29,656 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:16:29,657 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:16:29,657 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:16:29,686 - INFO - Using device: cuda
2025-12-11 00:16:30,332 - INFO - Loading dataset: pho_mt
2025-12-11 00:16:30,367 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:16:30,607 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:16:31,628 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:16:31,629 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:18:54,687 - INFO - ==================================================
2025-12-11 00:18:54,687 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:18:54,687 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:18:54,687 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:18:54,690 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:18:54,690 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:18:54,690 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:18:54,712 - INFO - Using device: cuda
2025-12-11 00:18:55,363 - INFO - Loading dataset: pho_mt
2025-12-11 00:18:55,397 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:18:55,637 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:18:56,661 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:18:56,661 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:21:33,199 - INFO - ==================================================
2025-12-11 00:21:33,199 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:21:33,200 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:21:33,200 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:21:33,202 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:21:33,202 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:21:33,202 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:21:33,215 - INFO - Using device: cuda
2025-12-11 00:21:33,852 - INFO - Loading dataset: pho_mt
2025-12-11 00:21:33,886 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:21:34,122 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:21:35,072 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:21:35,073 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:23:24,559 - INFO - ==================================================
2025-12-11 00:23:24,560 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:23:24,561 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:23:24,561 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:23:24,562 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:23:24,562 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:23:24,562 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:23:24,574 - INFO - Using device: cuda
2025-12-11 00:23:25,284 - INFO - Loading dataset: pho_mt
2025-12-11 00:23:25,321 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:23:25,560 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:23:26,551 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:23:26,551 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:24:01,181 - INFO - ==================================================
2025-12-11 00:24:01,181 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:24:01,181 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:24:01,181 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:24:01,181 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:24:01,181 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:24:01,181 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:24:01,200 - INFO - Using device: cuda
2025-12-11 00:24:01,974 - INFO - Loading dataset: pho_mt
2025-12-11 00:24:02,012 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:24:02,260 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:24:03,240 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:24:03,240 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:24:36,608 - INFO - ==================================================
2025-12-11 00:24:36,608 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:24:36,608 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:24:36,608 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:24:36,608 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:24:36,608 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:24:36,608 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:24:36,630 - INFO - Using device: cuda
2025-12-11 00:24:37,291 - INFO - Loading dataset: pho_mt
2025-12-11 00:24:37,328 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:24:37,564 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:24:38,559 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:24:38,559 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:27:24,165 - INFO - ==================================================
2025-12-11 00:27:24,165 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:27:24,165 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:27:24,165 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:27:24,167 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:27:24,167 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:27:24,167 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:27:24,177 - INFO - Using device: cuda
2025-12-11 00:27:24,885 - INFO - Loading dataset: pho_mt
2025-12-11 00:27:24,923 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:27:25,171 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:27:26,323 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:27:26,323 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:27:55,049 - INFO - ==================================================
2025-12-11 00:28:13,306 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:28:13,306 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:28:13,306 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:28:19,205 - INFO - ==================================================
2025-12-11 00:28:19,205 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:28:19,205 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:28:19,205 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:28:19,205 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:28:19,205 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:28:19,205 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:28:19,232 - INFO - Using device: cuda
2025-12-11 00:28:19,938 - INFO - Loading dataset: pho_mt
2025-12-11 00:28:19,979 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:28:20,254 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:28:21,372 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:28:21,372 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:28:32,939 - INFO - ==================================================
2025-12-11 00:28:32,939 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:28:32,939 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:28:32,939 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:28:32,943 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:28:32,943 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:28:32,943 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:28:32,958 - INFO - Using device: cuda
2025-12-11 00:28:33,671 - INFO - Loading dataset: pho_mt
2025-12-11 00:28:33,706 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:28:33,970 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:28:35,320 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:28:35,320 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:29:54,822 - INFO - ==================================================
2025-12-11 00:29:54,822 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:29:54,822 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:29:54,822 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:29:54,822 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:29:54,822 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:29:54,822 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:29:54,837 - INFO - Using device: cuda
2025-12-11 00:29:55,587 - INFO - Loading dataset: pho_mt
2025-12-11 00:29:55,631 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:29:55,887 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:29:57,149 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:29:57,151 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:32:43,569 - INFO - ==================================================
2025-12-11 00:32:43,569 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:32:43,569 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:32:43,569 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:32:43,585 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:32:43,585 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:32:43,585 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:32:43,585 - INFO - Using device: cuda
2025-12-11 00:32:44,302 - INFO - Loading dataset: pho_mt
2025-12-11 00:32:44,345 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:32:44,638 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:32:45,787 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:32:45,787 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:33:41,002 - INFO - ==================================================
2025-12-11 00:33:41,002 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:33:41,002 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:33:41,002 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:33:41,002 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:33:41,002 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:33:41,002 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:33:41,028 - INFO - Using device: cuda
2025-12-11 00:33:41,736 - INFO - Loading dataset: pho_mt
2025-12-11 00:33:41,775 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:33:42,035 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:33:43,203 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:33:43,203 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:38:11,416 - INFO - ==================================================
2025-12-11 00:38:11,416 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:38:11,416 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:38:11,416 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:38:11,416 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:38:11,416 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:38:11,416 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:38:11,436 - INFO - Using device: cuda
2025-12-11 00:38:12,066 - INFO - Loading dataset: pho_mt
2025-12-11 00:38:12,103 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:38:12,333 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:38:13,296 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:38:13,296 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:38:26,607 - INFO - ==================================================
2025-12-11 00:38:26,607 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:38:26,607 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:38:26,607 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:38:26,609 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:38:26,609 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:38:26,609 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:38:26,622 - INFO - Using device: cuda
2025-12-11 00:38:27,250 - INFO - Loading dataset: pho_mt
2025-12-11 00:38:27,299 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:38:27,545 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:38:28,549 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:38:28,549 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:39:59,625 - INFO - ==================================================
2025-12-11 00:39:59,625 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:39:59,625 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:39:59,625 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:39:59,625 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:39:59,625 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:39:59,625 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:39:59,683 - INFO - Using device: cuda
2025-12-11 00:40:00,496 - INFO - Loading dataset: pho_mt
2025-12-11 00:40:00,548 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:40:00,866 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:40:02,130 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:40:02,130 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:40:31,098 - INFO - ==================================================
2025-12-11 00:40:31,098 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:40:31,098 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:40:31,098 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:40:31,114 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:40:31,114 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:40:31,114 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:40:31,115 - INFO - Using device: cuda
2025-12-11 00:40:31,849 - INFO - Loading dataset: pho_mt
2025-12-11 00:40:31,885 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:40:32,149 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:40:33,314 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:40:33,314 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:43:04,757 - INFO - ==================================================
2025-12-11 00:43:04,757 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:43:04,757 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:43:04,757 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:43:04,760 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:43:04,760 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:43:04,760 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:43:04,780 - INFO - Using device: cuda
2025-12-11 00:43:05,549 - INFO - Loading dataset: pho_mt
2025-12-11 00:43:05,590 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:43:05,862 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:43:07,030 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:43:07,030 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:43:36,144 - INFO - ==================================================
2025-12-11 00:43:36,144 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:43:36,144 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:43:36,144 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:43:36,147 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:43:36,147 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:43:36,147 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:43:36,162 - INFO - Using device: cuda
2025-12-11 00:43:36,859 - INFO - Loading dataset: pho_mt
2025-12-11 00:43:36,900 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:43:37,163 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:43:38,330 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:43:38,343 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:44:50,303 - INFO - ==================================================
2025-12-11 00:44:50,303 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:44:50,303 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:44:50,303 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:44:50,303 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:44:50,303 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:44:50,303 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:44:50,320 - INFO - Using device: cuda
2025-12-11 00:44:50,975 - INFO - Loading dataset: pho_mt
2025-12-11 00:44:51,008 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:44:51,235 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:44:52,232 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:44:52,232 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:45:47,279 - INFO - ==================================================
2025-12-11 00:45:47,279 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:45:47,280 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:45:47,280 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:45:47,282 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:45:47,282 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:45:47,282 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:45:47,297 - INFO - Using device: cuda
2025-12-11 00:45:47,950 - INFO - Loading dataset: pho_mt
2025-12-11 00:45:47,979 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:45:48,212 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:45:49,195 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:45:49,195 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:46:49,548 - INFO - ==================================================
2025-12-11 00:46:49,548 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:46:49,548 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:46:49,548 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:46:49,548 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:46:49,548 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:46:49,548 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:46:49,566 - INFO - Using device: cuda
2025-12-11 00:46:50,241 - INFO - Loading dataset: pho_mt
2025-12-11 00:46:50,273 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:46:50,509 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:46:51,563 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:46:51,563 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:47:07,734 - INFO - ==================================================
2025-12-11 00:47:07,734 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:47:07,734 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:47:07,734 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:47:07,734 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:47:07,734 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:47:07,734 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:47:07,750 - INFO - Using device: cuda
2025-12-11 00:47:08,475 - INFO - Loading dataset: pho_mt
2025-12-11 00:47:08,513 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:47:08,762 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:47:09,777 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:47:09,777 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:49:13,867 - INFO - ==================================================
2025-12-11 00:49:13,867 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:49:13,867 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:49:13,867 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:49:13,867 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:49:13,867 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:49:13,867 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:49:13,885 - INFO - Using device: cuda
2025-12-11 00:49:14,548 - INFO - Loading dataset: pho_mt
2025-12-11 00:49:14,579 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:49:14,819 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:49:15,775 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:49:15,775 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:50:21,992 - INFO - ==================================================
2025-12-11 00:50:21,992 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:50:21,992 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:50:21,992 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:50:21,994 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:50:21,994 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:50:21,994 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:50:22,008 - INFO - Using device: cuda
2025-12-11 00:50:22,665 - INFO - Loading dataset: pho_mt
2025-12-11 00:50:22,699 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:50:22,926 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:50:23,930 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:50:23,930 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:51:05,408 - INFO - ==================================================
2025-12-11 00:51:05,408 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:51:05,408 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:51:05,408 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:51:05,408 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:51:05,408 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:51:05,408 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:51:05,423 - INFO - Using device: cuda
2025-12-11 00:51:06,074 - INFO - Loading dataset: pho_mt
2025-12-11 00:51:06,109 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:51:06,334 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:51:07,326 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:51:07,326 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:51:39,235 - INFO - ==================================================
2025-12-11 00:51:39,235 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:51:39,235 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:51:39,235 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:51:39,235 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:51:39,235 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:51:39,235 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:51:39,247 - INFO - Using device: cuda
2025-12-11 00:51:40,034 - INFO - Loading dataset: pho_mt
2025-12-11 00:51:40,072 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:51:40,334 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:51:41,396 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:51:41,396 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:51:46,360 - INFO - ==================================================
2025-12-11 00:51:46,360 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:51:46,360 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:51:46,360 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:51:46,360 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:51:46,360 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:51:46,360 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:51:46,378 - INFO - Using device: cuda
2025-12-11 00:51:47,058 - INFO - Loading dataset: pho_mt
2025-12-11 00:51:47,091 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:51:47,317 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:51:48,330 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:51:48,330 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:52:11,755 - INFO - ==================================================
2025-12-11 00:52:11,755 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:52:11,755 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:52:11,755 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:52:11,755 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:52:11,755 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:52:11,755 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:52:11,771 - INFO - Using device: cuda
2025-12-11 00:52:12,506 - INFO - Loading dataset: pho_mt
2025-12-11 00:52:12,541 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:52:12,774 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:52:13,802 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:52:13,802 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:53:34,423 - INFO - ==================================================
2025-12-11 00:53:34,423 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:53:34,423 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:53:34,423 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:53:34,423 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:53:34,423 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:53:34,423 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:53:34,423 - INFO - Using device: cuda
2025-12-11 00:53:35,090 - INFO - Loading dataset: pho_mt
2025-12-11 00:53:35,126 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:53:35,374 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:53:36,404 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:53:36,406 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:54:23,273 - INFO - ==================================================
2025-12-11 00:54:23,273 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:54:23,273 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:54:23,273 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:54:23,273 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:54:23,273 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:54:23,273 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:54:23,295 - INFO - Using device: cuda
2025-12-11 00:54:23,957 - INFO - Loading dataset: pho_mt
2025-12-11 00:54:23,990 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:54:24,243 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:54:25,439 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:54:25,439 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:57:01,655 - INFO - ==================================================
2025-12-11 00:57:01,655 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:57:01,655 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:57:01,655 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:57:01,655 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:57:01,662 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:57:01,662 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:57:01,675 - INFO - Using device: cuda
2025-12-11 00:57:02,337 - INFO - Loading dataset: pho_mt
2025-12-11 00:57:02,360 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:57:02,607 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:57:03,621 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:57:03,621 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:57:17,554 - INFO - ==================================================
2025-12-11 00:57:17,554 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:57:17,554 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:57:17,554 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:57:17,554 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:57:17,554 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:57:17,554 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:57:17,571 - INFO - Using device: cuda
2025-12-11 00:57:18,237 - INFO - Loading dataset: pho_mt
2025-12-11 00:57:18,272 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:57:18,518 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:57:19,471 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:57:19,471 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:58:46,466 - INFO - ==================================================
2025-12-11 00:58:46,466 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:58:46,466 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:58:46,466 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:58:46,469 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:58:46,469 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:58:46,470 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:58:46,482 - INFO - Using device: cuda
2025-12-11 00:58:47,102 - INFO - Loading dataset: pho_mt
2025-12-11 00:58:47,145 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:58:47,386 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:58:48,337 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:58:48,347 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 00:59:22,861 - INFO - ==================================================
2025-12-11 00:59:22,861 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 00:59:22,861 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 00:59:22,861 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 00:59:22,861 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 00:59:22,861 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 00:59:22,861 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 00:59:22,877 - INFO - Using device: cuda
2025-12-11 00:59:23,555 - INFO - Loading dataset: pho_mt
2025-12-11 00:59:23,605 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 00:59:23,856 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 00:59:24,865 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 00:59:24,865 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:03:29,133 - INFO - ==================================================
2025-12-11 01:03:29,133 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:03:29,133 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:03:29,134 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:03:29,134 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:03:29,136 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:03:29,136 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:03:29,136 - INFO - Using device: cuda
2025-12-11 01:03:29,784 - INFO - Loading dataset: pho_mt
2025-12-11 01:03:29,832 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:03:30,069 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:03:31,067 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:03:31,069 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:05:45,734 - INFO - ==================================================
2025-12-11 01:05:45,734 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:05:45,734 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:05:45,734 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:05:45,734 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:05:45,734 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:05:45,734 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:05:45,757 - INFO - Using device: cuda
2025-12-11 01:05:46,451 - INFO - Loading dataset: pho_mt
2025-12-11 01:05:46,493 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:05:46,757 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:05:47,749 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:05:47,749 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:06:51,854 - INFO - ==================================================
2025-12-11 01:06:51,854 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:06:51,854 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:06:51,854 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:06:51,854 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:06:51,854 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:06:51,854 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:06:51,871 - INFO - Using device: cuda
2025-12-11 01:06:52,528 - INFO - Loading dataset: pho_mt
2025-12-11 01:06:52,561 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:06:52,786 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:06:53,782 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:06:53,782 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:08:13,338 - INFO - ==================================================
2025-12-11 01:08:13,338 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:08:13,338 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:08:13,338 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:08:13,338 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:08:13,338 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:08:13,338 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:08:13,353 - INFO - Using device: cuda
2025-12-11 01:08:13,999 - INFO - Loading dataset: pho_mt
2025-12-11 01:08:14,032 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:08:14,265 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:08:15,242 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:08:15,242 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:08:48,015 - INFO - ==================================================
2025-12-11 01:08:48,015 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:08:48,015 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:08:48,015 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:08:48,015 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:08:48,015 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:08:48,015 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:08:48,030 - INFO - Using device: cuda
2025-12-11 01:08:48,666 - INFO - Loading dataset: pho_mt
2025-12-11 01:08:48,703 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:08:48,949 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:08:49,941 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:08:49,941 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:09:16,664 - INFO - ==================================================
2025-12-11 01:09:16,664 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:09:16,664 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:09:16,664 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:09:16,664 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:09:16,664 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:09:16,664 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:09:16,690 - INFO - Using device: cuda
2025-12-11 01:09:17,447 - INFO - Loading dataset: pho_mt
2025-12-11 01:09:17,485 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:09:17,732 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:09:18,914 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:09:18,914 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:10:29,115 - INFO - ==================================================
2025-12-11 01:10:29,115 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:10:29,115 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:10:29,115 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:10:29,115 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:10:29,115 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:10:29,115 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:10:29,137 - INFO - Using device: cuda
2025-12-11 01:10:29,848 - INFO - Loading dataset: pho_mt
2025-12-11 01:10:29,898 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:10:30,148 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:10:31,398 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:10:31,398 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:12:05,379 - INFO - ==================================================
2025-12-11 01:12:05,379 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:12:05,379 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:12:05,379 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:12:05,381 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:12:05,382 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:12:05,382 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:12:05,394 - INFO - Using device: cuda
2025-12-11 01:12:06,046 - INFO - Loading dataset: pho_mt
2025-12-11 01:12:06,084 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:12:06,314 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:12:07,287 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:12:07,287 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:12:53,112 - INFO - ==================================================
2025-12-11 01:12:53,128 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:12:53,128 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:12:53,128 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:12:53,128 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:12:53,128 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:12:53,128 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:12:53,141 - INFO - Using device: cuda
2025-12-11 01:12:53,827 - INFO - Loading dataset: pho_mt
2025-12-11 01:12:53,848 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:12:54,080 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:12:55,079 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:12:55,079 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:20:39,711 - INFO - ==================================================
2025-12-11 01:20:39,711 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:20:39,711 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:20:39,711 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:20:39,711 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:20:39,711 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:20:39,711 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:20:39,727 - INFO - Using device: cuda
2025-12-11 01:20:40,407 - INFO - Loading dataset: pho_mt
2025-12-11 01:20:40,447 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:20:40,697 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:20:41,791 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:20:41,791 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:21:19,024 - INFO - ==================================================
2025-12-11 01:21:19,024 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:21:19,024 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:21:19,024 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:21:19,024 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:21:19,024 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:21:19,024 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:21:19,040 - INFO - Using device: cuda
2025-12-11 01:21:19,727 - INFO - Loading dataset: pho_mt
2025-12-11 01:21:19,761 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:21:19,991 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:21:21,050 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:21:21,050 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:24:53,338 - INFO - ==================================================
2025-12-11 01:24:53,338 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:24:53,338 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:24:53,338 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:24:53,338 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:24:53,338 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:24:53,338 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:24:53,362 - INFO - Using device: cuda
2025-12-11 01:24:53,988 - INFO - Loading dataset: pho_mt
2025-12-11 01:24:54,027 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:24:54,267 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:24:55,264 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:24:55,264 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:25:44,387 - INFO - ==================================================
2025-12-11 01:25:44,387 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:25:44,387 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:25:44,387 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:25:44,387 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:25:44,387 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:25:44,387 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:25:44,407 - INFO - Using device: cuda
2025-12-11 01:25:45,054 - INFO - Loading dataset: pho_mt
2025-12-11 01:25:45,091 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:25:45,322 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:25:46,339 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:25:46,339 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:27:01,933 - INFO - ==================================================
2025-12-11 01:27:01,933 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:27:01,933 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:27:01,933 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:27:01,933 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:27:01,936 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:27:01,936 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:27:01,941 - INFO - Using device: cuda
2025-12-11 01:27:02,587 - INFO - Loading dataset: pho_mt
2025-12-11 01:27:02,622 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:27:02,851 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:27:03,843 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:27:03,844 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:27:32,972 - INFO - ==================================================
2025-12-11 01:27:32,972 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:27:32,972 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:27:32,972 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:27:32,972 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:27:32,972 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:27:32,972 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:27:32,988 - INFO - Using device: cuda
2025-12-11 01:27:33,640 - INFO - Loading dataset: pho_mt
2025-12-11 01:27:33,670 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:27:33,906 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:27:34,896 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:27:34,897 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:30:18,602 - INFO - ==================================================
2025-12-11 01:30:18,602 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:30:18,602 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:30:18,602 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:30:18,602 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:30:18,602 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:30:18,602 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:30:18,622 - INFO - Using device: cuda
2025-12-11 01:30:19,268 - INFO - Loading dataset: pho_mt
2025-12-11 01:30:19,301 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:30:19,536 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:30:20,542 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:30:20,544 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:37:07,031 - INFO - ==================================================
2025-12-11 01:37:07,031 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:37:07,031 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:37:07,031 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:37:07,031 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:37:07,031 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:37:07,031 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:37:07,053 - INFO - Using device: cuda
2025-12-11 01:37:07,764 - INFO - Loading dataset: pho_mt
2025-12-11 01:37:07,803 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:37:08,131 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:37:09,275 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:37:09,275 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:42:08,052 - INFO - ==================================================
2025-12-11 01:42:08,052 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:42:08,052 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:42:08,052 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:42:08,054 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:42:08,054 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:42:08,054 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:42:08,067 - INFO - Using device: cuda
2025-12-11 01:42:08,723 - INFO - Loading dataset: pho_mt
2025-12-11 01:42:08,756 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:42:09,012 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:42:10,008 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:42:10,009 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:47:14,013 - INFO - ==================================================
2025-12-11 01:47:14,013 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:47:14,013 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:47:14,013 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:47:14,014 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:47:14,015 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:47:14,015 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:47:14,027 - INFO - Using device: cuda
2025-12-11 01:47:14,703 - INFO - Loading dataset: pho_mt
2025-12-11 01:47:14,737 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:47:14,986 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:47:16,027 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:47:16,027 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 01:56:52,347 - INFO - ==================================================
2025-12-11 01:56:52,347 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 01:56:52,347 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 01:56:52,347 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 01:56:52,349 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 01:56:52,350 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 01:56:52,350 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 64, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 01:56:52,362 - INFO - Using device: cuda
2025-12-11 01:56:53,119 - INFO - Loading dataset: pho_mt
2025-12-11 01:56:53,154 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 01:56:53,406 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 01:56:54,517 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 01:56:54,517 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 02:27:50,345 - INFO - ==================================================
2025-12-11 02:27:50,345 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 02:27:50,345 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 02:27:50,351 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 02:27:50,351 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 02:27:50,351 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 02:27:50,351 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 8, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 02:27:50,361 - INFO - Using device: cuda
2025-12-11 02:27:51,285 - INFO - Loading dataset: pho_mt
2025-12-11 02:27:51,321 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 02:27:51,633 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 02:27:53,028 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 02:27:53,028 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
2025-12-11 02:28:18,802 - INFO - ==================================================
2025-12-11 02:28:18,802 - INFO - STARTING PROCESS FOR EXPERIMENT: LSTM_PhoMT
2025-12-11 02:28:18,802 - INFO - Log file location: ./results/machine_translation\LSTM_PhoMT_training.log
2025-12-11 02:28:18,802 - INFO - Loading configuration from: E:\DS201.Q11\DS201\Lab_4\config\LSTM.yml
2025-12-11 02:28:18,802 - INFO - 
Running Experiment: LSTM_PhoMT
2025-12-11 02:28:18,802 - INFO - Model: LSTM, Dataset: pho_mt
2025-12-11 02:28:18,802 - INFO - Hyperparameters: {'epochs': 50, 'early_stop_patience': 20, 'lr': 0.0001, 'weight_decay': 1e-05, 'batch_size': 16, 'optimizer': 'Adam', 'step_size': 30, 'gamma': 0.1, 'optimizer_params': {}, 'embedding_dim': 256, 'hidden_dim': 256, 'encoder_layers': 3, 'decoder_layers': 3, 'dropout': 0.1}
2025-12-11 02:28:18,821 - INFO - Using device: cuda
2025-12-11 02:28:19,517 - INFO - Loading dataset: pho_mt
2025-12-11 02:28:19,557 - INFO - Train: 20000, Val: 2000, Test: 2000
2025-12-11 02:28:19,802 - INFO - Using optimizer: Adam with LR=0.0001, WeightDecay=1e-05
2025-12-11 02:28:20,835 - INFO - START TRAINING LSTM_PhoMT...
2025-12-11 02:28:20,835 - INFO - No checkpoint found at ./checkpoints/LSTM_PhoMT/LSTM_PhoMT_last_checkpoint.pth
